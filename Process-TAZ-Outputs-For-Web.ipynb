{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- new data (RTP 2022) is from the remm se output\n",
    "- old data (RTP 2019) from wfrc data portal\n",
    "\n",
    "## How employment is calculated:\n",
    "\n",
    "**tdm_output['ALLEMP']** = tdm_output['RETL'] + tdm_output['FOOD'] + tdm_output['MANU'] + tdm_output['WSLE'] + tdm_output['OFFI'] + tdm_output['GVED'] + tdm_output['HLTH'] + tdm_output['OTHR'] + tdm_output['FM_AGRI'] + tdm_output['FM_MING'] + tdm_output['FM_CONS'] + tdm_output['HBJ']  \n",
    "    \n",
    "**tdm_output['RETEMP']** = tdm_output['RETL'] + tdm_output['FOOD']  \n",
    "**tdm_output['INDEMP']** = tdm_output['MANU'] + tdm_output['WSLE']  \n",
    "**tdm_output['OTHEMP']** = tdm_output['OFFI'] + tdm_output['GVED']+ tdm_output['HLTH'] + tdm_output['OTHR']  \n",
    "**tdm_output['TOTEMP']** = tdm_output['RETEMP'] + tdm_output['INDEMP']+ tdm_output['OTHEMP']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import glob\n",
    "from arcgis import GIS\n",
    "from arcgis.geometry import Geometry\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from datetime import date\n",
    "import shutil\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)\n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "taz832 = r\".\\Inputs\\TAZ_832_ID_Only.shp\"\n",
    "taz900 = r\".\\Inputs\\TAZ_900.gdb\\TAZ_UTM12\"\n",
    "city_areas = r\".\\Inputs\\TAZ_900.gdb\\CITYAREA_UTM12\"\n",
    "# other_areas = r\".\\Inputs\\TAZ_900.gdb\\OTHERAREA_UTM12\"\n",
    "med_districts = r\".\\Inputs\\TAZ_900.gdb\\DISTMED_UTM12\"\n",
    "counties = r\".\\Inputs\\TAZ_900.gdb\\COUNTY_UTM12\"\n",
    "# small_districts = ???\n",
    "\n",
    "\n",
    "taz832_sdf = pd.DataFrame.spatial.from_featureclass(taz832)\n",
    "taz900_sdf = pd.DataFrame.spatial.from_featureclass(taz900)[['SA_TAZID', 'DISTMED', 'CityArea', 'CO_NAME', 'DEVACRES','SHAPE']].copy()\n",
    "city_areas_sdf = pd.DataFrame.spatial.from_featureclass(city_areas)[['CityArea', 'DEVACRES','SHAPE']].copy()\n",
    "# other_areas_sdf = pd.DataFrame.spatial.from_featureclass(other_areas)[['OtherArea', 'DEVACRES','SHAPE']].copy()\n",
    "med_districts_sdf = pd.DataFrame.spatial.from_featureclass(med_districts)[['DISTMED', 'DEVACRES','SHAPE']].copy()\n",
    "counties_sdf = pd.DataFrame.spatial.from_featureclass(counties)[['CO_NAME', 'DEVACRES','SHAPE']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the paths to the new SE outputs\n",
    "new_se_folder = r\".\\New_SE_Data\"\n",
    "new_taz_se = glob.glob(os.path.join(new_se_folder,'taz900_SE_WF_*.csv'))\n",
    "# new_taz_se = glob.glob(os.path.join(new_se_folder,'SE_WF_*.csv'))\n",
    "len(new_taz_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the paths to the old SE outputs\n",
    "old_se_folder = r\".\\Old_SE_Data\"\n",
    "old_taz_se = glob.glob(os.path.join(old_se_folder,'*_TAZ.csv'))\n",
    "old_city_se = glob.glob(os.path.join(old_se_folder,'*_City_Area.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = r'.\\Outputs'\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)\n",
    "\n",
    "scratch = os.path.join(outputs, 'scratch.gdb')\n",
    "if not arcpy.Exists(scratch):\n",
    "    arcpy.CreateFileGDB_management(outputs, 'scratch.gdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process New SE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = taz900_sdf.copy()\n",
    "base.shape\n",
    "\n",
    "for csv in new_taz_se:\n",
    "\n",
    "    year = os.path.splitext(os.path.basename(csv))[0].split('_')[-1]\n",
    "    df = pd.read_csv(csv)\n",
    "    df['TPCL'] = df['TOTEMP']\n",
    "    df['HJI'] = df['TOTHH']*1.8 + df['TPCL']\n",
    "    df = df[[';TAZID', 'TOTHH', 'HHPOP', 'ALLEMP','RETEMP', 'INDEMP', 'OTHEMP', 'TPCL', 'HJI']].copy()\n",
    "    df.columns = ['SA_TAZID', f'HH_{year}', f'POP_{year}', f'AEMP_{year}', f'RTL_{year}', f'IND_{year}', f'OTHR_{year}', f'TPCL_{year}', f'HJI_{year}']\n",
    "    df = df[df['SA_TAZID']!= 2209]\n",
    "    base = base.copy().merge(df.copy(), on='SA_TAZID', how='left')\n",
    "\n",
    "new_se = base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049    1\n",
       "3239    1\n",
       "1170    1\n",
       "3219    1\n",
       "1174    1\n",
       "       ..\n",
       "597     1\n",
       "2648    1\n",
       "601     1\n",
       "2652    1\n",
       "2047    1\n",
       "Name: SA_TAZID, Length: 3546, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base['SA_TAZID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA_TAZID</th>\n",
       "      <th>DISTMED</th>\n",
       "      <th>CityArea</th>\n",
       "      <th>CO_NAME</th>\n",
       "      <th>DEVACRES</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>HH_2019</th>\n",
       "      <th>POP_2019</th>\n",
       "      <th>AEMP_2019</th>\n",
       "      <th>RTL_2019</th>\n",
       "      <th>IND_2019</th>\n",
       "      <th>OTHR_2019</th>\n",
       "      <th>TPCL_2019</th>\n",
       "      <th>HJI_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>791</td>\n",
       "      <td>22</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>549.188953</td>\n",
       "      <td>{'rings': [[[423442.2999999998, 4535297.300000...</td>\n",
       "      <td>280.0</td>\n",
       "      <td>991.297554</td>\n",
       "      <td>42.000697</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792</td>\n",
       "      <td>22</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>138.145710</td>\n",
       "      <td>{'rings': [[[424970.0999999996, 4534957], [424...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>470.119734</td>\n",
       "      <td>527.992395</td>\n",
       "      <td>18.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>622.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>793</td>\n",
       "      <td>22</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>351.696469</td>\n",
       "      <td>{'rings': [[[426304.0999999996, 4535305.800000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1059.999020</td>\n",
       "      <td>93.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>794</td>\n",
       "      <td>22</td>\n",
       "      <td>Centerville</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>652.764951</td>\n",
       "      <td>{'rings': [[[424952.9000000004, 4533883.800000...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>922.986629</td>\n",
       "      <td>3.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>795</td>\n",
       "      <td>22</td>\n",
       "      <td>Centerville</td>\n",
       "      <td>DAVIS</td>\n",
       "      <td>215.689740</td>\n",
       "      <td>{'rings': [[[425661.2000000002, 4533825], [425...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3316.000000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2987.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>3316.0</td>\n",
       "      <td>3316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>3390</td>\n",
       "      <td>61</td>\n",
       "      <td>Salem</td>\n",
       "      <td>UTAH</td>\n",
       "      <td>179.606935</td>\n",
       "      <td>{'rings': [[[441766.69319999963, 4435042.1359]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>3393</td>\n",
       "      <td>61</td>\n",
       "      <td>Salem</td>\n",
       "      <td>UTAH</td>\n",
       "      <td>120.172151</td>\n",
       "      <td>{'rings': [[[441780.07320000045, 4434227.7458]...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>3396</td>\n",
       "      <td>61</td>\n",
       "      <td>Salem</td>\n",
       "      <td>UTAH</td>\n",
       "      <td>153.092590</td>\n",
       "      <td>{'rings': [[[440833.7538999999, 4433839.116800...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>3397</td>\n",
       "      <td>61</td>\n",
       "      <td>Salem</td>\n",
       "      <td>UTAH</td>\n",
       "      <td>140.961646</td>\n",
       "      <td>{'rings': [[[440968.30319999997, 4432765.25249...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>2209</td>\n",
       "      <td>47</td>\n",
       "      <td>SL County East Cyns</td>\n",
       "      <td>SALT LAKE</td>\n",
       "      <td>185.921153</td>\n",
       "      <td>{'rings': [[[446211.5, 4505160], [446916.40000...</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1189.748871</td>\n",
       "      <td>178.016704</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>701.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3546 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SA_TAZID  DISTMED             CityArea    CO_NAME    DEVACRES  \\\n",
       "0          791       22           Farmington      DAVIS  549.188953   \n",
       "1          792       22           Farmington      DAVIS  138.145710   \n",
       "2          793       22           Farmington      DAVIS  351.696469   \n",
       "3          794       22          Centerville      DAVIS  652.764951   \n",
       "4          795       22          Centerville      DAVIS  215.689740   \n",
       "...        ...      ...                  ...        ...         ...   \n",
       "3541      3390       61                Salem       UTAH  179.606935   \n",
       "3542      3393       61                Salem       UTAH  120.172151   \n",
       "3543      3396       61                Salem       UTAH  153.092590   \n",
       "3544      3397       61                Salem       UTAH  140.961646   \n",
       "3545      2209       47  SL County East Cyns  SALT LAKE  185.921153   \n",
       "\n",
       "                                                  SHAPE  HH_2019     POP_2019  \\\n",
       "0     {'rings': [[[423442.2999999998, 4535297.300000...    280.0   991.297554   \n",
       "1     {'rings': [[[424970.0999999996, 4534957], [424...    134.0   470.119734   \n",
       "2     {'rings': [[[426304.0999999996, 4535305.800000...      0.0     0.000000   \n",
       "3     {'rings': [[[424952.9000000004, 4533883.800000...      0.0     0.000000   \n",
       "4     {'rings': [[[425661.2000000002, 4533825], [425...      0.0     0.000000   \n",
       "...                                                 ...      ...          ...   \n",
       "3541  {'rings': [[[441766.69319999963, 4435042.1359]...      NaN          NaN   \n",
       "3542  {'rings': [[[441780.07320000045, 4434227.7458]...      NaN          NaN   \n",
       "3543  {'rings': [[[440833.7538999999, 4433839.116800...      NaN          NaN   \n",
       "3544  {'rings': [[[440968.30319999997, 4432765.25249...      NaN          NaN   \n",
       "3545  {'rings': [[[446211.5, 4505160], [446916.40000...    301.0  1189.748871   \n",
       "\n",
       "        AEMP_2019  RTL_2019  IND_2019  OTHR_2019  TPCL_2019  HJI_2019  \n",
       "0       42.000697       8.0       0.0       16.0       24.0     528.0  \n",
       "1      527.992395      18.0     216.0      147.0      381.0     622.2  \n",
       "2     1059.999020      93.0     506.0      444.0     1043.0    1043.0  \n",
       "3      922.986629       3.0     444.0      244.0      691.0     691.0  \n",
       "4     3316.000000      22.0    2987.0      307.0     3316.0    3316.0  \n",
       "...           ...       ...       ...        ...        ...       ...  \n",
       "3541          NaN       NaN       NaN        NaN        NaN       NaN  \n",
       "3542          NaN       NaN       NaN        NaN        NaN       NaN  \n",
       "3543          NaN       NaN       NaN        NaN        NaN       NaN  \n",
       "3544          NaN       NaN       NaN        NaN        NaN       NaN  \n",
       "3545   178.016704      34.0      21.0      105.0      160.0     701.8  \n",
       "\n",
       "[3546 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = taz900_sdf.copy()\n",
    " \n",
    "csv = '.\\\\New_SE_Data\\\\taz900_SE_WF_2019.csv'\n",
    "year = os.path.splitext(os.path.basename(csv))[0].split('_')[-1]\n",
    "df = pd.read_csv(csv)\n",
    "df['TPCL'] = df['TOTEMP']\n",
    "df['HJI'] = df['TOTHH']*1.8 + df['TPCL']\n",
    "df = df[[';TAZID', 'TOTHH', 'HHPOP', 'ALLEMP','RETEMP', 'INDEMP', 'OTHEMP', 'TPCL', 'HJI']].copy()\n",
    "df.columns = ['SA_TAZID', f'HH_{year}', f'POP_{year}', f'AEMP_{year}', f'RTL_{year}', f'IND_{year}', f'OTHR_{year}', f'TPCL_{year}', f'HJI_{year}']\n",
    "\n",
    "base = base.merge(df, on='SA_TAZID', how='left')\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Process-SE-Output-For-Web\\\\Outputs\\\\scratch.gdb\\\\_01_new_se_taz_900'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "new_se_taz_900 = os.path.join(scratch, '_01_new_se_taz_900')\n",
    "new_se.spatial.to_featureclass(location=new_se_taz_900,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Old SE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_dict =  {'TOTHH':'HH',    \n",
    "            'HHPOP':'POP',\n",
    "            'RETEMP':'RTL',\n",
    "            'TOTEMP':'TPCL',\n",
    "            'ALLEMP':'AEMP',\n",
    "            'INDEMP':'IND',\n",
    "            'OTHEMP':'OTHR'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_base = taz832_sdf[['CO_TAZID','SHAPE']].copy()\n",
    "old_base.shape\n",
    "\n",
    "for csv in old_taz_se:\n",
    "\n",
    "    df = pd.read_csv(csv)\n",
    "    category = se_dict[df.iloc[0]['SECategory']]\n",
    "    val_cols = [col for col in list(df.columns) if 'YEAR' in col and  'D' not in col and int(col[4:]) >= 2019]\n",
    "    df = df[['CO_TAZID'] + val_cols]\n",
    "    new_val_cols = [col.replace('YEAR',category + '_') for col in val_cols]\n",
    "    df.columns = ['CO_TAZID'] + new_val_cols\n",
    "    old_base = old_base.merge(df, on='CO_TAZID',how='left')\n",
    "\n",
    "old_se = old_base\n",
    "old_se.rename({'CO_TAZID': 'COTAZID832'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate household jobs index\n",
    "for year in range(2019,2051):\n",
    "    old_se['HJI_{}'.format(year)] = (old_se['HH_{}'.format(year)] * 1.8) + old_se['TPCL_{}'.format(year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 258)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\REMM-Process-SE-Output-For-Web\\\\Outputs\\\\scratch.gdb\\\\_02_old_se_taz_832'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "old_se_taz_832 = os.path.join(scratch, '_02_old_se_taz_832')\n",
    "old_se.spatial.to_featureclass(location=old_se_taz_832,sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare output dimensions\n",
    "old_se.shape == new_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, September 9, 2022 4:51:48 PM\",\"Succeeded at Friday, September 9, 2022 4:53:14 PM (Elapsed Time: 1 minutes 26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\scratch.gdb\\\\_03_taz832_taz900_identity'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge geometry between taz 832 and output geometries (taz900, )\n",
    "taz900_identity = arcpy.Identity_analysis(taz900, old_se_taz_832, os.path.join(scratch, '_03_taz832_taz900_identity'))\n",
    "arcpy.management.DeleteField(taz900_identity,['SA_TAZID', 'DISTMED', 'CityArea', 'CO_NAME'], \"KEEP_FIELDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apportion the attributes from old geometry to the new ones\n",
    "\n",
    "1. The Apportion tool still does not work when used with Arcpy\n",
    "2. Open the Arcgis Pro, ensure the identity layer are present in the map\n",
    "3. Delete previous apportioning files if present\n",
    "4. Ensure *dissolve* layer and *identity* layer are present in the contents pane\n",
    "5. Paste the text from the file, \"apportion_command_for_arcgis_pro.txt\", in the Arcgis Pro python window to get the apportion output\n",
    "6. Close Arcgis Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.startfile(r\".\\REMM-Process-TAZ-Outputs-For-Web.aprx\")\n",
    "# os.startfile(r\".\\apportion_command_for_arcgis_pro_v2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment if this tool ever works again from arcpy\n",
    "# apportion = arcpy.ApportionPolygon_analysis(old_se_taz_832, app_columns, identity, os.path.join(outputs, 'old_se_apportion_to_taz900.shp'), \"AREA\", \"\", \"\", \"MAINTAIN_GEOMETRIES\") # uncomment \n",
    "old_taz_apportion = os.path.join(scratch,'_05_old_se_apportion_to_taz900')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolve to summarize at geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_columns = list(new_se.columns)[5:]\n",
    "stat_fields = [[col,'SUM'] for col in app_columns]\n",
    "\n",
    "#########\n",
    "# New\n",
    "#########\n",
    "\n",
    "# taz (9.0.0)\n",
    "new_se_taz900_dissolve = arcpy.Dissolve_management(new_se_taz_900, os.path.join(scratch, '_06_new_se_taz900_dissolve'),\n",
    "                          'SA_TAZID', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# distmed (9.0.0)\n",
    "new_se_distmed_dissolve = arcpy.Dissolve_management(new_se_taz_900, os.path.join(scratch, '_06_new_se_distmed_dissolve'),\n",
    "                          'DISTMED', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# city area\n",
    "new_se_cityarea_dissolve = arcpy.Dissolve_management(new_se_taz_900, os.path.join(scratch, '_06_new_se_cityarea_dissolve'),\n",
    "                          'CityArea', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# other area\n",
    "# new_se_otherarea_dissolve = arcpy.Dissolve_management(new_se_taz_900, os.path.join(scratch, '_06_new_se_otherarea_dissolve'),\n",
    "#                           'OtherArea', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# county\n",
    "new_se_county_dissolve = arcpy.Dissolve_management(new_se_taz_900, os.path.join(scratch, '_06_new_se_county_dissolve'),\n",
    "                          'CO_NAME', stat_fields, \"MULTI_PART\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Old\n",
    "#########\n",
    "\n",
    "# taz (9.0.0)\n",
    "old_se_taz900_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_taz900_dissolve'),\n",
    "                          'SA_TAZID', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# distmed (9.0.0)\n",
    "old_se_distmed_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_distmed_dissolve'),\n",
    "                          'DISTMED', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# city area\n",
    "old_se_cityarea_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_cityarea_dissolve'),\n",
    "                          'CityArea', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# # city area\n",
    "# old_se_otherarea_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_otherarea_dissolve'),\n",
    "#                           'OtherArea', stat_fields, \"MULTI_PART\")\n",
    "\n",
    "# county\n",
    "old_se_county_dissolve = arcpy.Dissolve_management(old_taz_apportion, os.path.join(scratch, '_06_old_se_county_dissolve'),\n",
    "                          'CO_NAME', stat_fields, \"MULTI_PART\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in new dataframes\n",
    "new_se_taz900_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_taz900_dissolve[0])\n",
    "new_se_distmed_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_distmed_dissolve[0])\n",
    "new_se_cityarea_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_cityarea_dissolve[0])\n",
    "new_se_county_dissolve_df = pd.DataFrame.spatial.from_featureclass(new_se_county_dissolve[0])\n",
    "old_se_taz900_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_taz900_dissolve[0])\n",
    "old_se_distmed_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_distmed_dissolve[0])\n",
    "old_se_cityarea_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_cityarea_dissolve[0])\n",
    "old_se_county_dissolve_df = pd.DataFrame.spatial.from_featureclass(old_se_county_dissolve[0])\n",
    "\n",
    "# fill NAs\n",
    "new_se_taz900_dissolve_df = fill_na_sedf(new_se_taz900_dissolve_df)\n",
    "new_se_distmed_dissolve_df = fill_na_sedf(new_se_distmed_dissolve_df)\n",
    "new_se_cityarea_dissolve_df = fill_na_sedf(new_se_cityarea_dissolve_df)\n",
    "new_se_county_dissolve_df = fill_na_sedf(new_se_county_dissolve_df)\n",
    "old_se_taz900_dissolve_df = fill_na_sedf(old_se_taz900_dissolve_df)\n",
    "old_se_distmed_dissolve_df = fill_na_sedf(old_se_distmed_dissolve_df)\n",
    "old_se_cityarea_dissolve_df = fill_na_sedf(old_se_cityarea_dissolve_df)\n",
    "old_se_county_dissolve_df = fill_na_sedf(old_se_county_dissolve_df)\n",
    "\n",
    "# round !! come up with something better\n",
    "new_se_taz900_dissolve_df = new_se_taz900_dissolve_df.round()\n",
    "new_se_distmed_dissolve_df = new_se_distmed_dissolve_df.round()\n",
    "new_se_cityarea_dissolve_df = new_se_cityarea_dissolve_df.round()\n",
    "new_se_county_dissolve_df = new_se_county_dissolve_df.round()\n",
    "old_se_taz900_dissolve_df = old_se_taz900_dissolve_df.round()\n",
    "old_se_distmed_dissolve_df = old_se_distmed_dissolve_df.round()\n",
    "old_se_cityarea_dissolve_df = old_se_cityarea_dissolve_df.round()\n",
    "old_se_county_dissolve_df = old_se_county_dissolve_df.round()\n",
    "\n",
    "# rename SA_TAZID column\n",
    "new_se_taz900_dissolve_df.rename({'SA_TAZID':'TAZID'}, axis=1, inplace=True)\n",
    "old_se_taz900_dissolve_df.rename({'SA_TAZID':'TAZID'}, axis=1, inplace=True)\n",
    "\n",
    "del new_se_distmed_dissolve_df['SHAPE']\n",
    "del old_se_distmed_dissolve_df['SHAPE']\n",
    "del new_se_cityarea_dissolve_df['SHAPE']\n",
    "del old_se_cityarea_dissolve_df['SHAPE']\n",
    "del new_se_county_dissolve_df['SHAPE']\n",
    "del old_se_county_dissolve_df['SHAPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'SUM' from column names\n",
    "to_replace = ['SUM_'+ col for col in app_columns]\n",
    "replace_dict = dict(zip(to_replace, app_columns))\n",
    "\n",
    "new_se_taz900_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "old_se_taz900_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "\n",
    "new_se_distmed_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "old_se_distmed_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "\n",
    "new_se_cityarea_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "old_se_cityarea_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "\n",
    "new_se_county_dissolve_df.rename(replace_dict, axis=1, inplace=True)\n",
    "old_se_county_dissolve_df.rename(replace_dict, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for deliverables\n",
    "map_folder = os.path.join(outputs, \"map\")\n",
    "if not os.path.exists(map_folder):\n",
    "    os.makedirs(map_folder)\n",
    "\n",
    "chart_folder = os.path.join(outputs, \"chart\")\n",
    "if not os.path.exists(chart_folder):\n",
    "    os.makedirs(chart_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================\n",
    "# Process TAZ to feature class\n",
    "#===============================\n",
    "\n",
    "taz900_sdf.rename({'SA_TAZID':'TAZID'}, axis=1, inplace=True)\n",
    "taz900_sdf = taz900_sdf[['TAZID', 'DEVACRES','SHAPE']].copy()\n",
    "\n",
    "taz_gdb = os.path.join(map_folder, 'TAZ.gdb')\n",
    "if not arcpy.Exists(taz_gdb):\n",
    "    arcpy.CreateFileGDB_management(map_folder, 'TAZ.gdb')\n",
    "\n",
    "\n",
    "categories = ['HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI']\n",
    "for c in categories:\n",
    "    new_cols = [col for col in app_columns if col.split('_')[0] == c]\n",
    "    new_temp_df = new_se_taz900_dissolve_df[['TAZID'] + new_cols].copy()\n",
    "    old_temp_df = old_se_taz900_dissolve_df[['TAZID'] + new_cols].copy()\n",
    "    \n",
    "\n",
    "    new_new_names = [col.replace(c, 'N') for col in new_cols]\n",
    "    new_old_names = [col.replace(c, 'O') for col in new_cols]\n",
    "    new_rename_dict = dict(zip(new_cols, new_new_names))\n",
    "    old_rename_dict = dict(zip(new_cols, new_old_names))\n",
    "    new_temp_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "    old_temp_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    merged = new_temp_df.merge(old_temp_df, on=['TAZID'], how='left')\n",
    "    merged = taz900_sdf.merge(merged, on='TAZID', how='left')\n",
    "\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].fillna(value=0)\n",
    "\n",
    "    merged.SHAPE.apply(Geometry)\n",
    "    merged.spatial.set_geometry(\"SHAPE\", inplace=True)\n",
    "    gsa = GeoSeriesAccessor(merged['SHAPE'])\n",
    "    merged['ACRES'] = gsa.area * 0.000247105\n",
    "    merged['ACRES'] = merged['ACRES'].astype(float).round(2)\n",
    "\n",
    "    outfile = os.path.join(taz_gdb, '{}_PROJECTIONS_by_TAZ'.format(c))\n",
    "    merged.spatial.to_featureclass(location=outfile, sanitize_columns=False)\n",
    "\n",
    "    # arcpy.AddField_management(outfile, \"ACRES\", \"FLOAT\")\n",
    "    # exp = \"round(!SHAPE.AREA@ACRES!,2)\"\n",
    "    # arcpy.CalculateField_management(outfile, \"ACRES\", exp, \"PYTHON3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================\n",
    "# Process DISTMED to feature class\n",
    "#=====================================\n",
    "\n",
    "distmed_gdb = os.path.join(map_folder, 'DISTMED.gdb')\n",
    "if not arcpy.Exists(distmed_gdb):\n",
    "    arcpy.CreateFileGDB_management(map_folder, 'DISTMED.gdb')\n",
    "\n",
    "categories = ['HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI']\n",
    "for c in categories:\n",
    "    new_cols = [col for col in app_columns if col.split('_')[0] == c]\n",
    "    new_temp_df = new_se_distmed_dissolve_df[['DISTMED'] + new_cols].copy()\n",
    "    old_temp_df = old_se_distmed_dissolve_df[['DISTMED'] + new_cols].copy()\n",
    "    \n",
    "\n",
    "    new_new_names = [col.replace(c, 'N') for col in new_cols]\n",
    "    new_old_names = [col.replace(c, 'O') for col in new_cols]\n",
    "    new_rename_dict = dict(zip(new_cols, new_new_names))\n",
    "    old_rename_dict = dict(zip(new_cols, new_old_names))\n",
    "    new_temp_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "    old_temp_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "    merged = new_temp_df.merge(old_temp_df, on='DISTMED', how='left')\n",
    "    merged = med_districts_sdf.merge(merged, on='DISTMED', how='left')\n",
    "\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].fillna(value=0)\n",
    "    \n",
    "    merged.SHAPE.apply(Geometry)\n",
    "    merged.spatial.set_geometry(\"SHAPE\", inplace=True)\n",
    "    gsa = GeoSeriesAccessor(merged['SHAPE'])\n",
    "    merged['ACRES'] = gsa.area * 0.000247105\n",
    "    merged['ACRES'] = merged['ACRES'].astype(float).round(2)\n",
    "\n",
    "    outfile = os.path.join(distmed_gdb, '{}_PROJECTIONS_by_DISTMED'.format(c))\n",
    "    merged.spatial.to_featureclass(location=outfile, sanitize_columns=False)\n",
    "\n",
    "    # arcpy.AddField_management(outfile, \"ACRES\", \"FLOAT\")\n",
    "    # exp = \"round(!SHAPE.AREA@ACRES!,2)\"\n",
    "    # arcpy.CalculateField_management(outfile, \"ACRES\", exp, \"PYTHON3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# Process City Area to feature class\n",
    "#====================================\n",
    "\n",
    "cityarea_gdb = os.path.join(map_folder, 'CITYAREA.gdb')\n",
    "if not arcpy.Exists(cityarea_gdb):\n",
    "    arcpy.CreateFileGDB_management(map_folder, 'CITYAREA.gdb')\n",
    "\n",
    "categories = ['HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI']\n",
    "for c in categories:\n",
    "    new_cols = [col for col in app_columns if col.split('_')[0] == c]\n",
    "    new_temp_df = new_se_cityarea_dissolve_df[['CityArea'] + new_cols].copy()\n",
    "    old_temp_df = old_se_cityarea_dissolve_df[['CityArea'] + new_cols].copy()\n",
    "    \n",
    "\n",
    "    new_new_names = [col.replace(c, 'N') for col in new_cols]\n",
    "    new_old_names = [col.replace(c, 'O') for col in new_cols]\n",
    "    new_rename_dict = dict(zip(new_cols, new_new_names))\n",
    "    old_rename_dict = dict(zip(new_cols, new_old_names))\n",
    "    new_temp_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "    old_temp_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "    merged = new_temp_df.merge(old_temp_df, on='CityArea', how='left')\n",
    "    merged = city_areas_sdf.merge(merged, on='CityArea', how='left')\n",
    "\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].fillna(value=0)\n",
    "\n",
    "    merged.SHAPE.apply(Geometry)\n",
    "    merged.spatial.set_geometry(\"SHAPE\", inplace=True)\n",
    "    gsa = GeoSeriesAccessor(merged['SHAPE'])\n",
    "    merged['ACRES'] = gsa.area * 0.000247105\n",
    "    merged['ACRES'] = merged['ACRES'].astype(float).round(2)\n",
    "\n",
    "    outfile = os.path.join(cityarea_gdb, '{}_PROJECTIONS_by_CITYAREA'.format(c))\n",
    "    merged.spatial.to_featureclass(location=outfile, sanitize_columns=False)\n",
    "\n",
    "    # arcpy.AddField_management(outfile, \"ACRES\", \"FLOAT\")\n",
    "    # exp = \"round(!SHAPE.AREA@ACRES!,2)\"\n",
    "    # arcpy.CalculateField_management(outfile, \"ACRES\", exp, \"PYTHON3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "# Process County to feature class\n",
    "#==================================\n",
    "\n",
    "county_gdb = os.path.join(map_folder, 'COUNTY.gdb')\n",
    "if not arcpy.Exists(county_gdb):\n",
    "    arcpy.CreateFileGDB_management(map_folder, 'COUNTY.gdb')\n",
    "\n",
    "categories = ['HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI']\n",
    "for c in categories:\n",
    "    new_cols = [col for col in app_columns if col.split('_')[0] == c]\n",
    "    new_temp_df = new_se_county_dissolve_df[['CO_NAME'] + new_cols].copy()\n",
    "    old_temp_df = old_se_county_dissolve_df[['CO_NAME'] + new_cols].copy()\n",
    "    \n",
    "\n",
    "    new_new_names = [col.replace(c, 'N') for col in new_cols]\n",
    "    new_old_names = [col.replace(c, 'O') for col in new_cols]\n",
    "    new_rename_dict = dict(zip(new_cols, new_new_names))\n",
    "    old_rename_dict = dict(zip(new_cols, new_old_names))\n",
    "    new_temp_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "    old_temp_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "    merged = new_temp_df.merge(old_temp_df, on='CO_NAME', how='left')\n",
    "    merged = counties_sdf.merge(merged, on='CO_NAME', how='left')\n",
    "\n",
    "    merged[new_new_names + new_old_names] = merged[new_new_names + new_old_names].fillna(value=0)\n",
    "    \n",
    "    merged.SHAPE.apply(Geometry)\n",
    "    merged.spatial.set_geometry(\"SHAPE\", inplace=True)\n",
    "    gsa = GeoSeriesAccessor(merged['SHAPE'])\n",
    "    merged['ACRES'] = gsa.area * 0.000247105\n",
    "    merged['ACRES'] = merged['ACRES'].astype(float).round(2)\n",
    "\n",
    "\n",
    "    outfile = os.path.join(county_gdb, '{}_PROJECTIONS_by_COUNTY'.format(c))\n",
    "    merged.spatial.to_featureclass(location=outfile, sanitize_columns=False)\n",
    "\n",
    "    # arcpy.AddField_management(outfile, \"ACRES\", \"FLOAT\")\n",
    "    # exp = \"round(!SHAPE.AREA@ACRES!,2)\"\n",
    "    # arcpy.CalculateField_management(outfile, \"ACRES\", exp, \"PYTHON3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'wkid': 26912, 'latestWkid': 26912}\n",
       "1    {'wkid': 26912, 'latestWkid': 26912}\n",
       "2    {'wkid': 26912, 'latestWkid': 26912}\n",
       "3    {'wkid': 26912, 'latestWkid': 26912}\n",
       "4    {'wkid': 26912, 'latestWkid': 26912}\n",
       "Name: spatial_reference, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsa.spatial_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================\n",
    "# Process TAZ to json\n",
    "#=======================\n",
    "\n",
    "chart_taz_folder = os.path.join(chart_folder, 'TAZ')\n",
    "if not os.path.exists(chart_taz_folder):\n",
    "    os.makedirs(chart_taz_folder)\n",
    "else:\n",
    "    shutil.rmtree(chart_taz_folder)\n",
    "    os.makedirs(chart_taz_folder)\n",
    "\n",
    "new_df = new_se_taz900_dissolve_df.copy()\n",
    "old_df = old_se_taz900_dissolve_df.copy()\n",
    "id_col = 'TAZID'\n",
    "\n",
    "categories = ('HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI')\n",
    "cols = [col for col in new_df.columns if col.startswith(categories)]\n",
    "new_new_cols = ['NEW_' + col for col in cols]\n",
    "old_new_cols = ['OLD_' + col for col in cols]\n",
    "\n",
    "new_rename_dict = dict(zip(cols, new_new_cols))\n",
    "old_rename_dict = dict(zip(cols, old_new_cols))\n",
    "new_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "old_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "del new_df['SHAPE']\n",
    "del old_df['SHAPE']\n",
    "\n",
    "df = new_df.merge(old_df, on=id_col, how='left')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "        f = open(os.path.join(chart_taz_folder, \"TAZ_{}.json\".format(int(row[id_col]))), \"a\")\n",
    "        f.write(\"[\\n\")\n",
    "        \n",
    "        for cat in categories:  \n",
    "            for year in range(2019,2051):\n",
    "                \n",
    "                new_col = '_'.join(['NEW', cat, str(year)])\n",
    "                old_col = '_'.join(['OLD', cat, str(year)])\n",
    "\n",
    "                f.write(\"\\t{\\n\")\n",
    "                f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(cat))\n",
    "                f.write('''\\t\\t\"Y\":{},\\n'''.format(year))\n",
    "                \n",
    "                f.write('''\\t\\t\"N\":{},\\n'''.format(row[new_col]))\n",
    "                f.write('''\\t\\t\"O\":{}\\n'''.format(row[old_col]))\n",
    "        \n",
    "                if cat == \"HJI\" and year == 2050:\n",
    "                    f.write(\"\\t}\\n\")\n",
    "                else:\n",
    "                    f.write(\"\\t},\\n\")\n",
    "\n",
    "        f.write(\"]\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================\n",
    "# Process DISTMED to json\n",
    "#==========================\n",
    "\n",
    "chart_DISTMED_folder = os.path.join(chart_folder, 'DISTMED')\n",
    "if not os.path.exists(chart_DISTMED_folder):\n",
    "    os.makedirs(chart_DISTMED_folder)\n",
    "else:\n",
    "    shutil.rmtree(chart_DISTMED_folder)\n",
    "    os.makedirs(chart_DISTMED_folder)\n",
    "\n",
    "new_df = new_se_distmed_dissolve_df.copy()\n",
    "old_df = old_se_distmed_dissolve_df.copy()\n",
    "id_col = 'DISTMED'\n",
    "\n",
    "categories = ('HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI')\n",
    "cols = [col for col in new_df.columns if col.startswith(categories)]\n",
    "new_new_cols = ['NEW_' + col for col in cols]\n",
    "old_new_cols = ['OLD_' + col for col in cols]\n",
    "\n",
    "new_rename_dict = dict(zip(cols, new_new_cols))\n",
    "old_rename_dict = dict(zip(cols, old_new_cols))\n",
    "new_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "old_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "df = new_df.merge(old_df, on=id_col, how='left')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "        f = open(os.path.join(chart_DISTMED_folder, \"{}_{}.json\".format(id_col,int(row[id_col]))), \"a\")\n",
    "        f.write(\"[\\n\")\n",
    "        \n",
    "        for cat in categories:  \n",
    "            for year in range(2019,2051):\n",
    "                \n",
    "                new_col = '_'.join(['NEW', cat, str(year)])\n",
    "                old_col = '_'.join(['OLD', cat, str(year)])\n",
    "\n",
    "                f.write(\"\\t{\\n\")\n",
    "                f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(cat))\n",
    "                f.write('''\\t\\t\"Y\":{},\\n'''.format(year))\n",
    "                \n",
    "                f.write('''\\t\\t\"N\":{},\\n'''.format(row[new_col]))\n",
    "                f.write('''\\t\\t\"O\":{}\\n'''.format(row[old_col]))\n",
    "        \n",
    "                if cat == \"HJI\" and year == 2050:\n",
    "                    f.write(\"\\t}\\n\")\n",
    "                else:\n",
    "                    f.write(\"\\t},\\n\")\n",
    "\n",
    "        f.write(\"]\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================\n",
    "# Process CITYAREA to json\n",
    "#===========================\n",
    "\n",
    "chart_CITYAREA_folder = os.path.join(chart_folder, 'CITYAREA')\n",
    "if not os.path.exists(chart_CITYAREA_folder):\n",
    "    os.makedirs(chart_CITYAREA_folder)\n",
    "else:\n",
    "    shutil.rmtree(chart_CITYAREA_folder)\n",
    "    os.makedirs(chart_CITYAREA_folder)\n",
    "\n",
    "\n",
    "new_df = new_se_cityarea_dissolve_df.copy()\n",
    "old_df = old_se_cityarea_dissolve_df.copy()\n",
    "id_col = 'CityArea'\n",
    "\n",
    "categories = ('HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI')\n",
    "cols = [col for col in new_df.columns if col.startswith(categories)]\n",
    "new_new_cols = ['NEW_' + col for col in cols]\n",
    "old_new_cols = ['OLD_' + col for col in cols]\n",
    "\n",
    "new_rename_dict = dict(zip(cols, new_new_cols))\n",
    "old_rename_dict = dict(zip(cols, old_new_cols))\n",
    "new_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "old_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "df = new_df.merge(old_df, on=id_col, how='left')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "        f = open(os.path.join(chart_CITYAREA_folder, \"{}_{}.json\".format(id_col,row[id_col])), \"a\")\n",
    "        f.write(\"[\\n\")\n",
    "        \n",
    "        for cat in categories:  \n",
    "            for year in range(2019,2051):\n",
    "                \n",
    "                new_col = '_'.join(['NEW', cat, str(year)])\n",
    "                old_col = '_'.join(['OLD', cat, str(year)])\n",
    "\n",
    "                f.write(\"\\t{\\n\")\n",
    "                f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(cat))\n",
    "                f.write('''\\t\\t\"Y\":{},\\n'''.format(year))\n",
    "                \n",
    "                f.write('''\\t\\t\"N\":{},\\n'''.format(row[new_col]))\n",
    "                f.write('''\\t\\t\"O\":{}\\n'''.format(row[old_col]))\n",
    "        \n",
    "                if cat == \"HJI\" and year == 2050:\n",
    "                    f.write(\"\\t}\\n\")\n",
    "                else:\n",
    "                    f.write(\"\\t},\\n\")\n",
    "\n",
    "        f.write(\"]\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================\n",
    "# Process COUNTY to json\n",
    "#===========================\n",
    "\n",
    "chart_COUNTY_folder = os.path.join(chart_folder, 'COUNTY')\n",
    "if not os.path.exists(chart_COUNTY_folder):\n",
    "    os.makedirs(chart_COUNTY_folder)\n",
    "else:\n",
    "    shutil.rmtree(chart_COUNTY_folder)\n",
    "    os.makedirs(chart_COUNTY_folder)\n",
    "\n",
    "\n",
    "new_df = new_se_county_dissolve_df.copy()\n",
    "old_df = old_se_county_dissolve_df.copy()\n",
    "id_col = 'CO_NAME'\n",
    "\n",
    "categories = ('HH', 'POP', 'AEMP', 'RTL', 'IND', 'OTHR', 'TPCL', 'HJI')\n",
    "cols = [col for col in new_df.columns if col.startswith(categories)]\n",
    "new_new_cols = ['NEW_' + col for col in cols]\n",
    "old_new_cols = ['OLD_' + col for col in cols]\n",
    "\n",
    "new_rename_dict = dict(zip(cols, new_new_cols))\n",
    "old_rename_dict = dict(zip(cols, old_new_cols))\n",
    "new_df.rename(new_rename_dict, axis=1, inplace=True)\n",
    "old_df.rename(old_rename_dict, axis=1, inplace=True)\n",
    "\n",
    "df = new_df.merge(old_df, on=id_col, how='left')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "        f = open(os.path.join(chart_COUNTY_folder, \"{}_{}.json\".format(id_col,row[id_col])), \"a\")\n",
    "        f.write(\"[\\n\")\n",
    "        \n",
    "        for cat in categories:  \n",
    "            for year in range(2019,2051):\n",
    "                \n",
    "                new_col = '_'.join(['NEW', cat, str(year)])\n",
    "                old_col = '_'.join(['OLD', cat, str(year)])\n",
    "\n",
    "                f.write(\"\\t{\\n\")\n",
    "                f.write('''\\t\\t\"C\":\"{}\",\\n'''.format(cat))\n",
    "                f.write('''\\t\\t\"Y\":{},\\n'''.format(year))\n",
    "                \n",
    "                f.write('''\\t\\t\"N\":{},\\n'''.format(row[new_col]))\n",
    "                f.write('''\\t\\t\"O\":{}\\n'''.format(row[old_col]))\n",
    "        \n",
    "                if cat == \"HJI\" and year == 2050:\n",
    "                    f.write(\"\\t}\\n\")\n",
    "                else:\n",
    "                    f.write(\"\\t},\\n\")\n",
    "\n",
    "        f.write(\"]\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================\n",
    "# add files to zipped folder\n",
    "#==============================\n",
    "\n",
    "d = date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "def zipdir(path, ziph, ext=None):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if ext:\n",
    "            files = [ fi for fi in files if fi.endswith(ext) ]\n",
    "\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(map_folder,'CITYAREA.gdb.zip'),'w', zipfile.ZIP_DEFLATED) as zip_cityarea:\n",
    "    zipdir(cityarea_gdb, zip_cityarea)\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(map_folder,'COUNTY.gdb.zip'),'w', zipfile.ZIP_DEFLATED) as zip_county:\n",
    "    zipdir(county_gdb, zip_county)\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(map_folder,'DISTMED.gdb.zip'),'w', zipfile.ZIP_DEFLATED) as zip_distmed:\n",
    "    zipdir(distmed_gdb, zip_distmed)\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(map_folder,'TAZ.gdb.zip'),'w', zipfile.ZIP_DEFLATED) as zip_taz:\n",
    "    zipdir(taz_gdb, zip_taz)\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(os.path.join('.\\\\Outputs','Files_For_Web_App_{}.zip'.format(d)),'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipdir(chart_folder, zipf)\n",
    "    zipdir(map_folder, zipf, ext='.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcba146b744ef62af8ef1a169a65f5cba67ffcb67445c2d993d6e4d88fe0ea63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
